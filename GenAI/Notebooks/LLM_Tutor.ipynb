{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cd6be86-faae-4792-90f6-211ab89b237c",
   "metadata": {},
   "source": [
    "LLM Tutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a03f9cfd-07d2-4623-b260-b80311b3288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n",
    "\n",
    "load_dotenv(override='True')\n",
    "api_key=os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d955bda0-1b02-488b-9ddb-fdc23c0e28a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_to_qusetion(question):\n",
    "    model='gpt-4o-mini'\n",
    "    system_prompt =\"You are an virtual assistant that works as a tutor for Data Science and Data Engineering. \\\n",
    "                    You respond to questions asked by students. \\\n",
    "                    Respond in markdown\"\n",
    "    user_prompt=\"You have been asked this question :\"\n",
    "    user_prompt+=f\"\\n {question}\"\n",
    "    messages = [\n",
    "                {\"role\":\"system\",\"content\":system_prompt},\n",
    "                {\"role\":\"user\",\"content\":user_prompt_q(question)}    \n",
    "               ]\n",
    "    stream = openai.chat.completions.create(model=model,messages=messages,stream=True)\n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Certainly! The code snippet you've shared is using Python's generator functionality along with a set comprehension. Here’s a breakdown of what it does:\n",
       "\n",
       "### Code Breakdown\n",
       "\n",
       "python\n",
       "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "\n",
       "\n",
       "1. **Set Comprehension**:\n",
       "   - The code `{book.get(\"author\") for book in books if book.get(\"author\")}` creates a set of authors.\n",
       "   - It iterates over each `book` in the `books` iterable.\n",
       "   - `book.get(\"author\")` retrieves the value associated with the key `\"author\"` for each `book`.\n",
       "   - The `if book.get(\"author\")` condition ensures that only books with a valid author (i.e., not `None` or an empty string) are included in the set.\n",
       "\n",
       "2. **Set Usage**:\n",
       "   - The set is used here to ensure that each author is unique in the output. If multiple books have the same author, that author will only appear once in the set.\n",
       "\n",
       "3. **Yield From**:\n",
       "   - `yield from` is a keyword used in Python to yield values from a generator. In this case, it allows the function that contains this code to yield each author from the created set one by one.\n",
       "   - This is useful in a generator function where you want to yield values from another iterable or generator without needing to loop through it manually.\n",
       "\n",
       "### Why Use This Code?\n",
       "\n",
       "- **Efficiency**: It creates a unique list of authors (thanks to the set) while automatically filtering out any books without an author, thus saving processing time and space.\n",
       "- **Generators**: By using `yield from`, it maintains the generator’s state and allows the caller to iterate through the authors seamlessly as if they were directly yielding from a larger collection.\n",
       "- **Clarity**: This approach is often cleaner and more readable than using traditional loops to achieve the same result.\n",
       "\n",
       "### Example\n",
       "\n",
       "Here’s a small example to illustrate how this would work:\n",
       "\n",
       "python\n",
       "books = [\n",
       "    {\"title\": \"Book 1\", \"author\": \"Author A\"},\n",
       "    {\"title\": \"Book 2\", \"author\": \"Author B\"},\n",
       "    {\"title\": \"Book 3\", \"author\": None},\n",
       "    {\"title\": \"Book 4\", \"author\": \"Author A\"},\n",
       "    {\"title\": \"Book 5\", \"author\": \"\"}\n",
       "]\n",
       "\n",
       "def unique_authors(books):\n",
       "    yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "\n",
       "# Usage\n",
       "for author in unique_authors(books):\n",
       "    print(author)\n",
       "\n",
       "\n",
       "### Output\n",
       "\n",
       "Author A\n",
       "Author B\n",
       "\n",
       "\n",
       "In this example, when you call `unique_authors(books)`, it yields \"Author A\" and \"Author B\", with \"Author A\" appearing only once in the output, demonstrating the uniqueness of set elements."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "\n",
    "answer_to_qusetion(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
